{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12187eaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mnemoliaev\\AppData\\Roaming\\Python\\Python39\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mnemoliaev\\AppData\\Roaming\\Python\\Python39\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 236      |\n",
      "|    ep_rew_mean      | 9        |\n",
      "|    exploration_rate | 0.551    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 53       |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 945      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0212   |\n",
      "|    n_updates        | 211      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 252      |\n",
      "|    ep_rew_mean      | 10.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 48       |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 2012     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0244   |\n",
      "|    n_updates        | 477      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 278      |\n",
      "|    ep_rew_mean      | 10.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 90       |\n",
      "|    total_timesteps  | 3336     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0371   |\n",
      "|    n_updates        | 808      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 284      |\n",
      "|    ep_rew_mean      | 10.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 152      |\n",
      "|    total_timesteps  | 4547     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 1111     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 285      |\n",
      "|    ep_rew_mean      | 10.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 26       |\n",
      "|    time_elapsed     | 212      |\n",
      "|    total_timesteps  | 5692     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0149   |\n",
      "|    n_updates        | 1397     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 288      |\n",
      "|    ep_rew_mean      | 11.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 25       |\n",
      "|    time_elapsed     | 274      |\n",
      "|    total_timesteps  | 6900     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00148  |\n",
      "|    n_updates        | 1699     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 287      |\n",
      "|    ep_rew_mean      | 11.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 24       |\n",
      "|    time_elapsed     | 334      |\n",
      "|    total_timesteps  | 8026     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0161   |\n",
      "|    n_updates        | 1981     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 288      |\n",
      "|    ep_rew_mean      | 11.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 23       |\n",
      "|    time_elapsed     | 396      |\n",
      "|    total_timesteps  | 9202     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00891  |\n",
      "|    n_updates        | 2275     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 285      |\n",
      "|    ep_rew_mean      | 11.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 22       |\n",
      "|    time_elapsed     | 450      |\n",
      "|    total_timesteps  | 10248    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0299   |\n",
      "|    n_updates        | 2536     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 278      |\n",
      "|    ep_rew_mean      | 11.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 22       |\n",
      "|    time_elapsed     | 495      |\n",
      "|    total_timesteps  | 11111    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00244  |\n",
      "|    n_updates        | 2752     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 272      |\n",
      "|    ep_rew_mean      | 11.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 22       |\n",
      "|    time_elapsed     | 539      |\n",
      "|    total_timesteps  | 11962    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 2965     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 270      |\n",
      "|    ep_rew_mean      | 11.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 21       |\n",
      "|    time_elapsed     | 591      |\n",
      "|    total_timesteps  | 12944    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0333   |\n",
      "|    n_updates        | 3210     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 267      |\n",
      "|    ep_rew_mean      | 11.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 21       |\n",
      "|    time_elapsed     | 643      |\n",
      "|    total_timesteps  | 13904    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00512  |\n",
      "|    n_updates        | 3450     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 264      |\n",
      "|    ep_rew_mean      | 11.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 21       |\n",
      "|    time_elapsed     | 690      |\n",
      "|    total_timesteps  | 14780    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00722  |\n",
      "|    n_updates        | 3669     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 263      |\n",
      "|    ep_rew_mean      | 11.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 20       |\n",
      "|    time_elapsed     | 754      |\n",
      "|    total_timesteps  | 15753    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0289   |\n",
      "|    n_updates        | 3913     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 262      |\n",
      "|    ep_rew_mean      | 12       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 20       |\n",
      "|    time_elapsed     | 832      |\n",
      "|    total_timesteps  | 16737    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0165   |\n",
      "|    n_updates        | 4159     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 260      |\n",
      "|    ep_rew_mean      | 12.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 19       |\n",
      "|    time_elapsed     | 912      |\n",
      "|    total_timesteps  | 17696    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00653  |\n",
      "|    n_updates        | 4398     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 260      |\n",
      "|    ep_rew_mean      | 12       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 18       |\n",
      "|    time_elapsed     | 991      |\n",
      "|    total_timesteps  | 18684    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00991  |\n",
      "|    n_updates        | 4645     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 259      |\n",
      "|    ep_rew_mean      | 12.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 18       |\n",
      "|    time_elapsed     | 1068     |\n",
      "|    total_timesteps  | 19669    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00501  |\n",
      "|    n_updates        | 4892     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mnemoliaev\\AppData\\Roaming\\Python\\Python39\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mnemoliaev\\AppData\\Roaming\\Python\\Python39\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 12.2\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "# Define the rgb_to_gray function\n",
    "def rgb_to_gray(rgb_array):\n",
    "    return np.dot(rgb_array[..., :3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "# Create Frogger environment\n",
    "env = gym.make('ALE/Frogger-v5', render_mode=\"rgb_array\")\n",
    "\n",
    "# Create DQN agent with a smaller buffer size\n",
    "model = DQN('CnnPolicy', env, buffer_size=60000, verbose=1)\n",
    "\n",
    "# Train the agent\n",
    "model.learn(total_timesteps=20000)\n",
    "\n",
    "# Evaluate the agent\n",
    "mean_reward, _ = evaluate_policy(model, env, n_eval_episodes=10)\n",
    "print(f\"Mean reward: {mean_reward}\")\n",
    "\n",
    "# Save the model\n",
    "model.save(\"frogger_dqn_model_stable_baselines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d019c80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "# Create Frogger environment\n",
    "env = gym.make('ALE/Frogger-v5', render_mode=\"rgb_array\")\n",
    "\n",
    "# Load the model\n",
    "model = DQN.load('frogger_dqn_model_stable_baselines', env=env)\n",
    "\n",
    "# Train the agent (optional)\n",
    "model.learn(total_timesteps=10000)\n",
    "\n",
    "# Evaluate the agent\n",
    "mean_reward, _ = evaluate_policy(model, env, n_eval_episodes=10)\n",
    "print(f\"Mean reward: {mean_reward}\")\n",
    "\n",
    "# Save the model (optional)\n",
    "model.save(\"frogger_dqn_model_stable_baselines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6a8fb01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bc2e85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
