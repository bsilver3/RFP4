{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "from collections import deque\n",
    "from gymnasium.wrappers import FrameStack\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants and hyperparameters\n",
    "num_episodes = 1000 # Make sure you change this to 10000 for the final training sequence, and either 1000 or 100 for smaller testing\n",
    "max_steps_per_episode = 1000\n",
    "learning_rate = 0.001 # Use 0.0001 for 10000 episodes, 0.001 for 1000 episodes, and 0.01 for 100 episodes\n",
    "batch_size = 64\n",
    "gamma = 0.99  # Discount factor\n",
    "epsilon = 1.0  # Exploration rate\n",
    "epsilon_min = 0.01\n",
    "epsilon_decay = 0.995 # Use 0.995 for 10000 episodes, 0.985 for 1000 episodes, 0.975 for 100 episodes\n",
    "memory = deque(maxlen=10000)  # Experience replay buffer\n",
    "env_name = \"ALE/Frogger-v5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, num_actions):\n",
    "    model = Sequential([ # Each person should change the amount of Conv2D/Dense layers, as well as the filter amount and kernel_size/strides\n",
    "        Conv2D(32, kernel_size=(8, 8), strides=(4, 4), activation='relu', input_shape=input_shape, data_format=\"channels_first\"),\n",
    "        Conv2D(64, kernel_size=(4, 4), strides=(2, 2), activation='relu'),\n",
    "        Conv2D(64, kernel_size=(3, 3), strides=(1, 1), activation='relu'),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dense(num_actions, activation='linear')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the environment\n",
    "env = gym.make(env_name, obs_type='grayscale')\n",
    "num_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = FrameStack(env, 4)\n",
    "frames, width, height = env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the DQN model\n",
    "model = build_model((frames, width, height), num_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   0%|          | 1/1000 [00:22<6:20:34, 22.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 1/1000, Total Reward: 9.0, Epsilon: 0.9850"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   0%|          | 2/1000 [00:44<6:03:49, 21.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 2/1000, Total Reward: 10.0, Epsilon: 0.9702"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   0%|          | 3/1000 [01:05<5:58:11, 21.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 3/1000, Total Reward: 12.0, Epsilon: 0.9557"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   0%|          | 4/1000 [01:27<6:01:54, 21.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 4/1000, Total Reward: 7.0, Epsilon: 0.9413"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   0%|          | 5/1000 [01:52<6:21:08, 22.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 5/1000, Total Reward: 9.0, Epsilon: 0.9272"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   1%|          | 6/1000 [02:16<6:26:29, 23.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 6/1000, Total Reward: 10.0, Epsilon: 0.9133"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   1%|          | 7/1000 [02:39<6:24:17, 23.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 7/1000, Total Reward: 10.0, Epsilon: 0.8996"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   1%|          | 8/1000 [03:03<6:27:23, 23.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 8/1000, Total Reward: 8.0, Epsilon: 0.8861"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   1%|          | 9/1000 [03:40<7:38:12, 27.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 9/1000, Total Reward: 9.0, Epsilon: 0.8728"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   1%|          | 10/1000 [04:19<8:32:46, 31.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 10/1000, Total Reward: 10.0, Epsilon: 0.8597"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   1%|          | 11/1000 [04:57<9:09:20, 33.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 11/1000, Total Reward: 9.0, Epsilon: 0.8468"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   1%|          | 12/1000 [05:38<9:46:15, 35.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 12/1000, Total Reward: 7.0, Epsilon: 0.8341"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   1%|▏         | 13/1000 [06:16<9:56:48, 36.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 13/1000, Total Reward: 6.0, Epsilon: 0.8216"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   1%|▏         | 14/1000 [06:58<10:25:27, 38.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 14/1000, Total Reward: 14.0, Epsilon: 0.8093"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   2%|▏         | 15/1000 [07:41<10:50:59, 39.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 15/1000, Total Reward: 12.0, Epsilon: 0.7972"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   2%|▏         | 16/1000 [08:21<10:52:41, 39.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 16/1000, Total Reward: 10.0, Epsilon: 0.7852"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   2%|▏         | 17/1000 [09:00<10:45:57, 39.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 17/1000, Total Reward: 12.0, Epsilon: 0.7734"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   2%|▏         | 18/1000 [09:31<10:01:59, 36.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 18/1000, Total Reward: 8.0, Epsilon: 0.7618"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   2%|▏         | 19/1000 [10:02<9:34:58, 35.17s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 19/1000, Total Reward: 13.0, Epsilon: 0.7504"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   2%|▏         | 20/1000 [10:29<8:54:44, 32.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 20/1000, Total Reward: 12.0, Epsilon: 0.7391"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   2%|▏         | 21/1000 [10:59<8:41:22, 31.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 21/1000, Total Reward: 13.0, Epsilon: 0.7280"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   2%|▏         | 22/1000 [11:32<8:46:16, 32.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 22/1000, Total Reward: 8.0, Epsilon: 0.7171"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   2%|▏         | 23/1000 [12:04<8:41:48, 32.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 23/1000, Total Reward: 10.0, Epsilon: 0.7064"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   2%|▏         | 24/1000 [12:34<8:30:42, 31.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 24/1000, Total Reward: 13.0, Epsilon: 0.6958"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   2%|▎         | 25/1000 [13:07<8:40:17, 32.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 25/1000, Total Reward: 7.0, Epsilon: 0.6853"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   3%|▎         | 26/1000 [13:42<8:54:26, 32.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 26/1000, Total Reward: 9.0, Epsilon: 0.6751"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   3%|▎         | 27/1000 [14:16<9:00:57, 33.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 27/1000, Total Reward: 10.0, Epsilon: 0.6649"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   3%|▎         | 28/1000 [14:48<8:51:17, 32.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 28/1000, Total Reward: 10.0, Epsilon: 0.6550"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   3%|▎         | 29/1000 [15:23<9:03:05, 33.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 29/1000, Total Reward: 9.0, Epsilon: 0.6451"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   3%|▎         | 30/1000 [15:57<9:04:20, 33.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 30/1000, Total Reward: 10.0, Epsilon: 0.6355"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   3%|▎         | 31/1000 [16:35<9:25:50, 35.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 31/1000, Total Reward: 11.0, Epsilon: 0.6259"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   3%|▎         | 32/1000 [17:07<9:10:21, 34.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 32/1000, Total Reward: 9.0, Epsilon: 0.6165"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   3%|▎         | 33/1000 [17:40<9:01:37, 33.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 33/1000, Total Reward: 7.0, Epsilon: 0.6073"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   3%|▎         | 34/1000 [18:22<9:41:10, 36.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 34/1000, Total Reward: 8.0, Epsilon: 0.5982"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   4%|▎         | 35/1000 [18:57<9:38:45, 35.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 35/1000, Total Reward: 8.0, Epsilon: 0.5892"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   4%|▎         | 36/1000 [19:33<9:35:03, 35.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 36/1000, Total Reward: 8.0, Epsilon: 0.5804"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   4%|▎         | 37/1000 [20:08<9:30:03, 35.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 37/1000, Total Reward: 7.0, Epsilon: 0.5717"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   4%|▍         | 38/1000 [20:47<9:46:34, 36.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 38/1000, Total Reward: 9.0, Epsilon: 0.5631"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   4%|▍         | 39/1000 [21:22<9:40:19, 36.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 39/1000, Total Reward: 7.0, Epsilon: 0.5546"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   4%|▍         | 40/1000 [22:01<9:53:09, 37.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 40/1000, Total Reward: 11.0, Epsilon: 0.5463"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   4%|▍         | 41/1000 [22:40<9:59:24, 37.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 41/1000, Total Reward: 8.0, Epsilon: 0.5381"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   4%|▍         | 42/1000 [23:12<9:34:11, 35.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 42/1000, Total Reward: 10.0, Epsilon: 0.5301"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   4%|▍         | 43/1000 [23:46<9:26:15, 35.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 43/1000, Total Reward: 7.0, Epsilon: 0.5221"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   4%|▍         | 44/1000 [24:19<9:10:28, 34.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 44/1000, Total Reward: 8.0, Epsilon: 0.5143"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   4%|▍         | 45/1000 [24:55<9:18:59, 35.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 45/1000, Total Reward: 13.0, Epsilon: 0.5066"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   5%|▍         | 46/1000 [25:39<9:59:19, 37.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 46/1000, Total Reward: 11.0, Epsilon: 0.4990"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   5%|▍         | 47/1000 [26:14<9:47:28, 36.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 47/1000, Total Reward: 10.0, Epsilon: 0.4915"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   5%|▍         | 48/1000 [26:57<10:13:00, 38.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 48/1000, Total Reward: 13.0, Epsilon: 0.4841"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   5%|▍         | 49/1000 [27:32<9:58:27, 37.76s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 49/1000, Total Reward: 10.0, Epsilon: 0.4768"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   5%|▌         | 50/1000 [28:09<9:51:43, 37.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 50/1000, Total Reward: 10.0, Epsilon: 0.4697"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   5%|▌         | 51/1000 [28:50<10:08:09, 38.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 51/1000, Total Reward: 10.0, Epsilon: 0.4626"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   5%|▌         | 52/1000 [29:29<10:08:51, 38.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 52/1000, Total Reward: 8.0, Epsilon: 0.4557"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   5%|▌         | 53/1000 [30:11<10:27:05, 39.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 53/1000, Total Reward: 10.0, Epsilon: 0.4489"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   5%|▌         | 54/1000 [30:49<10:18:30, 39.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 54/1000, Total Reward: 6.0, Epsilon: 0.4421"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   6%|▌         | 55/1000 [31:30<10:24:52, 39.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 55/1000, Total Reward: 13.0, Epsilon: 0.4355"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   6%|▌         | 56/1000 [32:11<10:31:11, 40.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 56/1000, Total Reward: 7.0, Epsilon: 0.4290"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   6%|▌         | 57/1000 [33:06<11:41:05, 44.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 57/1000, Total Reward: 9.0, Epsilon: 0.4225"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   6%|▌         | 58/1000 [34:11<13:16:31, 50.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 58/1000, Total Reward: 11.0, Epsilon: 0.4162"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   6%|▌         | 59/1000 [35:14<14:11:08, 54.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 59/1000, Total Reward: 7.0, Epsilon: 0.4100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   6%|▌         | 60/1000 [36:18<14:58:28, 57.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 60/1000, Total Reward: 9.0, Epsilon: 0.4038"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   6%|▌         | 61/1000 [37:15<14:55:01, 57.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 61/1000, Total Reward: 8.0, Epsilon: 0.3977"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   6%|▌         | 62/1000 [38:06<14:26:42, 55.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 62/1000, Total Reward: 8.0, Epsilon: 0.3918"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   6%|▋         | 63/1000 [39:01<14:20:45, 55.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 63/1000, Total Reward: 6.0, Epsilon: 0.3859"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   6%|▋         | 64/1000 [39:52<14:01:39, 53.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 64/1000, Total Reward: 6.0, Epsilon: 0.3801"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   6%|▋         | 65/1000 [40:51<14:25:10, 55.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 65/1000, Total Reward: 7.0, Epsilon: 0.3744"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   7%|▋         | 66/1000 [41:43<14:06:37, 54.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 66/1000, Total Reward: 10.0, Epsilon: 0.3688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   7%|▋         | 67/1000 [42:49<15:01:55, 58.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 67/1000, Total Reward: 15.0, Epsilon: 0.3633"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   7%|▋         | 68/1000 [43:56<15:41:11, 60.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 68/1000, Total Reward: 10.0, Epsilon: 0.3578"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   7%|▋         | 69/1000 [44:49<15:03:27, 58.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 69/1000, Total Reward: 7.0, Epsilon: 0.3525"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   7%|▋         | 70/1000 [45:39<14:26:35, 55.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 70/1000, Total Reward: 11.0, Epsilon: 0.3472"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   7%|▋         | 71/1000 [46:36<14:29:59, 56.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 71/1000, Total Reward: 8.0, Epsilon: 0.3420"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   7%|▋         | 72/1000 [47:40<15:07:11, 58.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 72/1000, Total Reward: 10.0, Epsilon: 0.3368"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   7%|▋         | 73/1000 [48:33<14:35:48, 56.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 73/1000, Total Reward: 7.0, Epsilon: 0.3318"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   7%|▋         | 74/1000 [49:29<14:33:47, 56.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 74/1000, Total Reward: 8.0, Epsilon: 0.3268"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   8%|▊         | 75/1000 [50:19<14:04:00, 54.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 75/1000, Total Reward: 8.0, Epsilon: 0.3219"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   8%|▊         | 76/1000 [51:14<14:04:14, 54.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 76/1000, Total Reward: 9.0, Epsilon: 0.3171"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   8%|▊         | 77/1000 [52:38<16:16:14, 63.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 77/1000, Total Reward: 8.0, Epsilon: 0.3123"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   8%|▊         | 78/1000 [53:54<17:13:13, 67.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 78/1000, Total Reward: 9.0, Epsilon: 0.3076"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   8%|▊         | 79/1000 [54:58<16:55:34, 66.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 79/1000, Total Reward: 9.0, Epsilon: 0.3030"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   8%|▊         | 80/1000 [55:56<16:19:10, 63.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 80/1000, Total Reward: 9.0, Epsilon: 0.2985"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   8%|▊         | 81/1000 [56:53<15:45:59, 61.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 81/1000, Total Reward: 8.0, Epsilon: 0.2940"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   8%|▊         | 82/1000 [57:58<15:57:05, 62.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 82/1000, Total Reward: 8.0, Epsilon: 0.2896"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   8%|▊         | 83/1000 [59:34<18:29:37, 72.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 83/1000, Total Reward: 12.0, Epsilon: 0.2852"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   8%|▊         | 84/1000 [1:00:33<17:30:17, 68.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 84/1000, Total Reward: 11.0, Epsilon: 0.2810"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   8%|▊         | 85/1000 [1:01:34<16:50:01, 66.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 85/1000, Total Reward: 9.0, Epsilon: 0.2767"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   9%|▊         | 86/1000 [1:02:40<16:49:25, 66.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 86/1000, Total Reward: 10.0, Epsilon: 0.2726"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   9%|▊         | 87/1000 [1:03:39<16:16:45, 64.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 87/1000, Total Reward: 6.0, Epsilon: 0.2685"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   9%|▉         | 88/1000 [1:04:57<17:15:36, 68.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 88/1000, Total Reward: 13.0, Epsilon: 0.2645"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   9%|▉         | 89/1000 [1:06:10<17:36:06, 69.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 89/1000, Total Reward: 8.0, Epsilon: 0.2605"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   9%|▉         | 90/1000 [1:07:25<18:00:10, 71.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 90/1000, Total Reward: 11.0, Epsilon: 0.2566"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   9%|▉         | 91/1000 [1:08:38<18:10:29, 71.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 91/1000, Total Reward: 9.0, Epsilon: 0.2528"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   9%|▉         | 92/1000 [1:10:03<19:07:15, 75.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 92/1000, Total Reward: 11.0, Epsilon: 0.2490"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   9%|▉         | 93/1000 [1:11:13<18:38:19, 73.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 93/1000, Total Reward: 7.0, Epsilon: 0.2452"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   9%|▉         | 94/1000 [1:12:25<18:29:22, 73.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 94/1000, Total Reward: 9.0, Epsilon: 0.2415"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  10%|▉         | 95/1000 [1:13:28<17:37:50, 70.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 95/1000, Total Reward: 8.0, Epsilon: 0.2379"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  10%|▉         | 96/1000 [1:14:52<18:41:45, 74.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 96/1000, Total Reward: 9.0, Epsilon: 0.2344"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  10%|▉         | 97/1000 [1:16:37<20:58:57, 83.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 97/1000, Total Reward: 8.0, Epsilon: 0.2308"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  10%|▉         | 98/1000 [1:17:55<20:31:37, 81.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 98/1000, Total Reward: 11.0, Epsilon: 0.2274"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  10%|▉         | 99/1000 [1:19:05<19:33:58, 78.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 99/1000, Total Reward: 10.0, Epsilon: 0.2240"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  10%|█         | 100/1000 [1:20:33<20:20:02, 81.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 100/1000, Total Reward: 9.0, Epsilon: 0.2206"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  10%|█         | 101/1000 [1:21:46<19:41:12, 78.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 101/1000, Total Reward: 6.0, Epsilon: 0.2173"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  10%|█         | 102/1000 [1:23:03<19:30:20, 78.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 102/1000, Total Reward: 10.0, Epsilon: 0.2140"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  10%|█         | 103/1000 [1:24:45<21:15:00, 85.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 103/1000, Total Reward: 8.0, Epsilon: 0.2108"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  10%|█         | 104/1000 [1:25:59<20:23:51, 81.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 104/1000, Total Reward: 7.0, Epsilon: 0.2077"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  10%|█         | 105/1000 [1:27:23<20:30:06, 82.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 105/1000, Total Reward: 8.0, Epsilon: 0.2046"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  11%|█         | 106/1000 [1:28:41<20:10:04, 81.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 106/1000, Total Reward: 7.0, Epsilon: 0.2015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  11%|█         | 107/1000 [1:30:11<20:47:17, 83.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 107/1000, Total Reward: 11.0, Epsilon: 0.1985"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  11%|█         | 108/1000 [1:31:25<20:02:38, 80.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 108/1000, Total Reward: 8.0, Epsilon: 0.1955"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  11%|█         | 109/1000 [1:33:02<21:12:53, 85.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 109/1000, Total Reward: 12.0, Epsilon: 0.1926"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  11%|█         | 110/1000 [1:34:25<20:59:41, 84.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 110/1000, Total Reward: 8.0, Epsilon: 0.1897"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  11%|█         | 111/1000 [1:35:51<21:04:28, 85.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 111/1000, Total Reward: 9.0, Epsilon: 0.1868"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  11%|█         | 112/1000 [1:37:23<21:30:39, 87.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 112/1000, Total Reward: 11.0, Epsilon: 0.1840"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  11%|█▏        | 113/1000 [1:39:01<22:19:28, 90.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 113/1000, Total Reward: 8.0, Epsilon: 0.1813"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  11%|█▏        | 114/1000 [1:40:53<23:51:21, 96.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 114/1000, Total Reward: 8.0, Epsilon: 0.1785"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  12%|█▏        | 115/1000 [1:42:47<25:06:46, 102.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 115/1000, Total Reward: 11.0, Epsilon: 0.1759"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  12%|█▏        | 116/1000 [1:44:32<25:17:15, 102.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 116/1000, Total Reward: 5.0, Epsilon: 0.1732"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  12%|█▏        | 117/1000 [1:45:55<23:45:53, 96.89s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 117/1000, Total Reward: 9.0, Epsilon: 0.1706"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  12%|█▏        | 118/1000 [1:48:22<27:24:36, 111.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 118/1000, Total Reward: 7.0, Epsilon: 0.1681"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  12%|█▏        | 119/1000 [1:49:39<24:50:31, 101.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 119/1000, Total Reward: 6.0, Epsilon: 0.1655"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  12%|█▏        | 120/1000 [1:50:54<22:51:17, 93.50s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 120/1000, Total Reward: 10.0, Epsilon: 0.1631"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  12%|█▏        | 121/1000 [1:52:08<21:25:06, 87.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 121/1000, Total Reward: 6.0, Epsilon: 0.1606"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  12%|█▏        | 122/1000 [1:53:36<21:25:49, 87.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 122/1000, Total Reward: 8.0, Epsilon: 0.1582"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  12%|█▏        | 123/1000 [1:54:52<20:32:25, 84.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 123/1000, Total Reward: 5.0, Epsilon: 0.1558"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  12%|█▏        | 124/1000 [1:56:22<20:55:12, 85.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 124/1000, Total Reward: 7.0, Epsilon: 0.1535"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  12%|█▎        | 125/1000 [1:57:52<21:10:51, 87.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 125/1000, Total Reward: 12.0, Epsilon: 0.1512"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  13%|█▎        | 126/1000 [1:59:11<20:32:06, 84.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 126/1000, Total Reward: 10.0, Epsilon: 0.1489"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  13%|█▎        | 127/1000 [2:00:31<20:12:34, 83.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 127/1000, Total Reward: 6.0, Epsilon: 0.1467"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  13%|█▎        | 128/1000 [2:01:48<19:44:55, 81.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 128/1000, Total Reward: 9.0, Epsilon: 0.1445"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  13%|█▎        | 129/1000 [2:03:19<20:21:32, 84.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 129/1000, Total Reward: 7.0, Epsilon: 0.1423"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  13%|█▎        | 130/1000 [2:05:20<23:02:59, 95.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 130/1000, Total Reward: 8.0, Epsilon: 0.1402"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  13%|█▎        | 131/1000 [2:06:40<21:55:15, 90.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 131/1000, Total Reward: 8.0, Epsilon: 0.1381"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  13%|█▎        | 132/1000 [2:07:58<20:54:14, 86.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 132/1000, Total Reward: 6.0, Epsilon: 0.1360"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  13%|█▎        | 133/1000 [2:09:32<21:24:53, 88.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 133/1000, Total Reward: 9.0, Epsilon: 0.1340"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  13%|█▎        | 134/1000 [2:11:00<21:22:36, 88.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 134/1000, Total Reward: 9.0, Epsilon: 0.1320"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  14%|█▎        | 135/1000 [2:12:18<20:33:19, 85.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 135/1000, Total Reward: 7.0, Epsilon: 0.1300"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  14%|█▎        | 136/1000 [2:14:18<22:57:53, 95.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 136/1000, Total Reward: 7.0, Epsilon: 0.1280"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  14%|█▎        | 137/1000 [2:15:57<23:14:32, 96.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 137/1000, Total Reward: 8.0, Epsilon: 0.1261"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  14%|█▍        | 138/1000 [2:17:33<23:08:46, 96.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 138/1000, Total Reward: 6.0, Epsilon: 0.1242"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  14%|█▍        | 139/1000 [2:18:57<22:10:59, 92.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 139/1000, Total Reward: 8.0, Epsilon: 0.1224"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  14%|█▍        | 140/1000 [2:20:37<22:40:24, 94.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 140/1000, Total Reward: 5.0, Epsilon: 0.1205"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  14%|█▍        | 141/1000 [2:22:12<22:40:56, 95.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 141/1000, Total Reward: 7.0, Epsilon: 0.1187"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  14%|█▍        | 142/1000 [2:23:38<21:58:44, 92.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 142/1000, Total Reward: 7.0, Epsilon: 0.1169"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  14%|█▍        | 143/1000 [2:25:06<21:38:39, 90.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 143/1000, Total Reward: 6.0, Epsilon: 0.1152"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  14%|█▍        | 144/1000 [2:27:11<24:01:44, 101.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 144/1000, Total Reward: 8.0, Epsilon: 0.1135"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  14%|█▍        | 145/1000 [2:28:59<24:31:44, 103.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 145/1000, Total Reward: 8.0, Epsilon: 0.1118"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  15%|█▍        | 146/1000 [2:30:32<23:44:49, 100.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 146/1000, Total Reward: 7.0, Epsilon: 0.1101"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  15%|█▍        | 147/1000 [2:32:50<26:23:37, 111.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 147/1000, Total Reward: 5.0, Epsilon: 0.1084"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  15%|█▍        | 148/1000 [2:35:18<28:59:17, 122.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 148/1000, Total Reward: 8.0, Epsilon: 0.1068"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:  15%|█▍        | 148/1000 [2:36:07<14:58:45, 63.29s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27140\\1819497335.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Exploration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mq_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq_values\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Exploitation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[0;32m    451\u001b[0m     ):\n\u001b[0;32m    452\u001b[0m         \u001b[1;31m# Create an iterator that yields batches of input data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m         epoch_iterator = TFEpochIterator(\n\u001b[0m\u001b[0;32m    454\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, distribute_strategy, *args, **kwargs)\u001b[0m\n\u001b[0;32m    634\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_distribute_strategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 636\u001b[1;33m         \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    637\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDistributedDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m             dataset = self._distribute_strategy.experimental_distribute_dataset(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_adapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tf_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0menumerate_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\trainers\\data_adapters\\array_data_adapter.py\u001b[0m in \u001b[0;36mget_tf_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[0mindices_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m         \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[0moptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\trainers\\data_adapters\\array_data_adapter.py\u001b[0m in \u001b[0;36mslice_inputs\u001b[1;34m(indices_dataset, inputs)\u001b[0m\n\u001b[0;32m    227\u001b[0m                     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExternalStatePolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIGNORE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m                 )\n\u001b[1;32m--> 229\u001b[1;33m             \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_options\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mwith_options\u001b[1;34m(self, options, name)\u001b[0m\n\u001b[0;32m   2965\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0man\u001b[0m \u001b[0moption\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mset\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0monce\u001b[0m \u001b[0mto\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnon\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mdefault\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2966\u001b[0m     \"\"\"\n\u001b[1;32m-> 2967\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_OptionsDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2968\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2969\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcardinality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, options, name)\u001b[0m\n\u001b[0;32m   4843\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4844\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4845\u001b[1;33m       variant_tensor = gen_dataset_ops.options_dataset(\n\u001b[0m\u001b[0;32m   4846\u001b[0m           \u001b[0minput_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions_pb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4847\u001b[0m           **self._common_args)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36moptions_dataset\u001b[1;34m(input_dataset, serialized_options, output_types, output_shapes, metadata, name)\u001b[0m\n\u001b[0;32m   4650\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4651\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4652\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   4653\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"OptionsDataset\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"serialized_options\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4654\u001b[0m         \u001b[0mserialized_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"output_types\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"output_shapes\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for episode in tqdm(range(num_episodes), desc='Episode Progress', position=0):\n",
    "    state, _ = env.reset()\n",
    "    episode_reward = 0\n",
    "    done = False\n",
    "\n",
    "    for step in range(max_steps_per_episode):\n",
    "        if np.random.rand() <= epsilon:\n",
    "            action = env.action_space.sample()  # Exploration\n",
    "        else:\n",
    "            q_values = model.predict(np.array([state]), verbose=None)[0]\n",
    "            action = np.argmax(q_values)  # Exploitation\n",
    "\n",
    "        # Ensure action is within bounds\n",
    "        action = np.clip(action, 0, num_actions - 1)\n",
    "\n",
    "        next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        episode_reward += reward\n",
    "\n",
    "        memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    # Experience replay\n",
    "    if len(memory) >= batch_size:\n",
    "        minibatch = random.sample(memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = reward + gamma * np.amax(model.predict(np.array([next_state]), verbose=None)[0])\n",
    "\n",
    "            target_f = model.predict(np.array([state]), verbose=None)\n",
    "            target_f[0][action] = target\n",
    "            model.fit(np.array([state]), target_f, epochs=1, verbose=None)\n",
    "\n",
    "    # Decay exploration rate\n",
    "    if epsilon > epsilon_min:\n",
    "        epsilon *= epsilon_decay\n",
    "\n",
    "    print(f\"\\rPrevious episode: Episode: {episode + 1}/{num_episodes}, Total Reward: {episode_reward}, Epsilon: {epsilon:.4f}\", end=\"\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('weights/brennan.weights.h5') # Change this to 'weights/[yourname].weights.h5'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
