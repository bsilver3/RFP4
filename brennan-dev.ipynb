{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "from collections import deque\n",
    "from gymnasium.wrappers import FrameStack\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants and hyperparameters\n",
    "num_episodes = 1000 # Make sure you change this to 10000 for the final training sequence, and either 1000 or 100 for smaller testing\n",
    "max_steps_per_episode = 1000\n",
    "learning_rate = 0.001 # Use 0.0001 for 10000 episodes, 0.001 for 1000 episodes, and 0.01 for 100 episodes\n",
    "batch_size = 64\n",
    "gamma = 0.99  # Discount factor\n",
    "epsilon = 1.0  # Exploration rate\n",
    "epsilon_min = 0.01\n",
    "epsilon_decay = 0.995 # Use 0.995 for 10000 episodes, 0.985 for 1000 episodes, 0.975 for 100 episodes\n",
    "memory = deque(maxlen=10000)  # Experience replay buffer\n",
    "env_name = \"ALE/Frogger-v5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, num_actions):\n",
    "    model = Sequential([ # Each person should change the amount of Conv2D/Dense layers, as well as the filter amount and kernel_size/strides\n",
    "        Conv2D(32, kernel_size=(8, 8), strides=(4, 4), activation='relu', input_shape=input_shape, data_format=\"channels_first\"),\n",
    "        Conv2D(64, kernel_size=(4, 4), strides=(2, 2), activation='relu'),\n",
    "        Conv2D(64, kernel_size=(3, 3), strides=(1, 1), activation='relu'),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dense(num_actions, activation='linear')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the environment\n",
    "env = gym.make(env_name, obs_type='grayscale')\n",
    "num_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = FrameStack(env, 4)\n",
    "frames, width, height = env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the DQN model\n",
    "model = build_model((frames, width, height), num_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   0%|          | 1/1000 [00:22<6:20:34, 22.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 1/1000, Total Reward: 9.0, Epsilon: 0.9850"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   0%|          | 2/1000 [00:44<6:03:49, 21.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 2/1000, Total Reward: 10.0, Epsilon: 0.9702"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   0%|          | 3/1000 [01:05<5:58:11, 21.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 3/1000, Total Reward: 12.0, Epsilon: 0.9557"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   0%|          | 4/1000 [01:27<6:01:54, 21.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 4/1000, Total Reward: 7.0, Epsilon: 0.9413"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   0%|          | 5/1000 [01:52<6:21:08, 22.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 5/1000, Total Reward: 9.0, Epsilon: 0.9272"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   1%|          | 6/1000 [02:16<6:26:29, 23.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 6/1000, Total Reward: 10.0, Epsilon: 0.9133"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   1%|          | 7/1000 [02:39<6:24:17, 23.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 7/1000, Total Reward: 10.0, Epsilon: 0.8996"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   1%|          | 8/1000 [03:03<6:27:23, 23.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 8/1000, Total Reward: 8.0, Epsilon: 0.8861"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   1%|          | 9/1000 [03:40<7:38:12, 27.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 9/1000, Total Reward: 9.0, Epsilon: 0.8728"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   1%|          | 10/1000 [04:19<8:32:46, 31.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 10/1000, Total Reward: 10.0, Epsilon: 0.8597"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   1%|          | 11/1000 [04:57<9:09:20, 33.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 11/1000, Total Reward: 9.0, Epsilon: 0.8468"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   1%|          | 12/1000 [05:38<9:46:15, 35.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 12/1000, Total Reward: 7.0, Epsilon: 0.8341"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   1%|▏         | 13/1000 [06:16<9:56:48, 36.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 13/1000, Total Reward: 6.0, Epsilon: 0.8216"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   1%|▏         | 14/1000 [06:58<10:25:27, 38.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 14/1000, Total Reward: 14.0, Epsilon: 0.8093"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   2%|▏         | 15/1000 [07:41<10:50:59, 39.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 15/1000, Total Reward: 12.0, Epsilon: 0.7972"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   2%|▏         | 16/1000 [08:21<10:52:41, 39.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 16/1000, Total Reward: 10.0, Epsilon: 0.7852"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   2%|▏         | 17/1000 [09:00<10:45:57, 39.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 17/1000, Total Reward: 12.0, Epsilon: 0.7734"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   2%|▏         | 18/1000 [09:31<10:01:59, 36.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 18/1000, Total Reward: 8.0, Epsilon: 0.7618"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   2%|▏         | 19/1000 [10:02<9:34:58, 35.17s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 19/1000, Total Reward: 13.0, Epsilon: 0.7504"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   2%|▏         | 20/1000 [10:29<8:54:44, 32.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 20/1000, Total Reward: 12.0, Epsilon: 0.7391"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   2%|▏         | 21/1000 [10:59<8:41:22, 31.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 21/1000, Total Reward: 13.0, Epsilon: 0.7280"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   2%|▏         | 22/1000 [11:32<8:46:16, 32.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 22/1000, Total Reward: 8.0, Epsilon: 0.7171"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   2%|▏         | 23/1000 [12:04<8:41:48, 32.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 23/1000, Total Reward: 10.0, Epsilon: 0.7064"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   2%|▏         | 24/1000 [12:34<8:30:42, 31.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 24/1000, Total Reward: 13.0, Epsilon: 0.6958"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   2%|▎         | 25/1000 [13:07<8:40:17, 32.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 25/1000, Total Reward: 7.0, Epsilon: 0.6853"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   3%|▎         | 26/1000 [13:42<8:54:26, 32.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 26/1000, Total Reward: 9.0, Epsilon: 0.6751"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   3%|▎         | 27/1000 [14:16<9:00:57, 33.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 27/1000, Total Reward: 10.0, Epsilon: 0.6649"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   3%|▎         | 28/1000 [14:48<8:51:17, 32.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 28/1000, Total Reward: 10.0, Epsilon: 0.6550"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   3%|▎         | 29/1000 [15:23<9:03:05, 33.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 29/1000, Total Reward: 9.0, Epsilon: 0.6451"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   3%|▎         | 30/1000 [15:57<9:04:20, 33.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 30/1000, Total Reward: 10.0, Epsilon: 0.6355"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   3%|▎         | 31/1000 [16:35<9:25:50, 35.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 31/1000, Total Reward: 11.0, Epsilon: 0.6259"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   3%|▎         | 32/1000 [17:07<9:10:21, 34.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 32/1000, Total Reward: 9.0, Epsilon: 0.6165"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   3%|▎         | 33/1000 [17:40<9:01:37, 33.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 33/1000, Total Reward: 7.0, Epsilon: 0.6073"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   3%|▎         | 34/1000 [18:22<9:41:10, 36.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 34/1000, Total Reward: 8.0, Epsilon: 0.5982"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   4%|▎         | 35/1000 [18:57<9:38:45, 35.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 35/1000, Total Reward: 8.0, Epsilon: 0.5892"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   4%|▎         | 36/1000 [19:33<9:35:03, 35.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 36/1000, Total Reward: 8.0, Epsilon: 0.5804"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   4%|▎         | 37/1000 [20:08<9:30:03, 35.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 37/1000, Total Reward: 7.0, Epsilon: 0.5717"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   4%|▍         | 38/1000 [20:47<9:46:34, 36.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 38/1000, Total Reward: 9.0, Epsilon: 0.5631"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   4%|▍         | 39/1000 [21:22<9:40:19, 36.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 39/1000, Total Reward: 7.0, Epsilon: 0.5546"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   4%|▍         | 40/1000 [22:01<9:53:09, 37.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 40/1000, Total Reward: 11.0, Epsilon: 0.5463"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   4%|▍         | 41/1000 [22:40<9:59:24, 37.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 41/1000, Total Reward: 8.0, Epsilon: 0.5381"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   4%|▍         | 42/1000 [23:12<9:34:11, 35.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 42/1000, Total Reward: 10.0, Epsilon: 0.5301"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   4%|▍         | 43/1000 [23:46<9:26:15, 35.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 43/1000, Total Reward: 7.0, Epsilon: 0.5221"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   4%|▍         | 44/1000 [24:19<9:10:28, 34.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 44/1000, Total Reward: 8.0, Epsilon: 0.5143"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   4%|▍         | 45/1000 [24:55<9:18:59, 35.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 45/1000, Total Reward: 13.0, Epsilon: 0.5066"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   5%|▍         | 46/1000 [25:39<9:59:19, 37.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 46/1000, Total Reward: 11.0, Epsilon: 0.4990"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   5%|▍         | 47/1000 [26:14<9:47:28, 36.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 47/1000, Total Reward: 10.0, Epsilon: 0.4915"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   5%|▍         | 48/1000 [26:57<10:13:00, 38.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 48/1000, Total Reward: 13.0, Epsilon: 0.4841"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   5%|▍         | 49/1000 [27:32<9:58:27, 37.76s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 49/1000, Total Reward: 10.0, Epsilon: 0.4768"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   5%|▌         | 50/1000 [28:09<9:51:43, 37.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 50/1000, Total Reward: 10.0, Epsilon: 0.4697"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   5%|▌         | 51/1000 [28:50<10:08:09, 38.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 51/1000, Total Reward: 10.0, Epsilon: 0.4626"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   5%|▌         | 52/1000 [29:29<10:08:51, 38.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 52/1000, Total Reward: 8.0, Epsilon: 0.4557"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   5%|▌         | 53/1000 [30:11<10:27:05, 39.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 53/1000, Total Reward: 10.0, Epsilon: 0.4489"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   5%|▌         | 54/1000 [30:49<10:18:30, 39.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 54/1000, Total Reward: 6.0, Epsilon: 0.4421"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   6%|▌         | 55/1000 [31:30<10:24:52, 39.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 55/1000, Total Reward: 13.0, Epsilon: 0.4355"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   6%|▌         | 56/1000 [32:11<10:31:11, 40.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 56/1000, Total Reward: 7.0, Epsilon: 0.4290"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   6%|▌         | 57/1000 [33:06<11:41:05, 44.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 57/1000, Total Reward: 9.0, Epsilon: 0.4225"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   6%|▌         | 58/1000 [34:11<13:16:31, 50.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 58/1000, Total Reward: 11.0, Epsilon: 0.4162"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   6%|▌         | 59/1000 [35:14<14:11:08, 54.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 59/1000, Total Reward: 7.0, Epsilon: 0.4100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   6%|▌         | 60/1000 [36:18<14:58:28, 57.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 60/1000, Total Reward: 9.0, Epsilon: 0.4038"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   6%|▌         | 61/1000 [37:15<14:55:01, 57.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 61/1000, Total Reward: 8.0, Epsilon: 0.3977"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   6%|▌         | 62/1000 [38:06<14:26:42, 55.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 62/1000, Total Reward: 8.0, Epsilon: 0.3918"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   6%|▋         | 63/1000 [39:01<14:20:45, 55.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 63/1000, Total Reward: 6.0, Epsilon: 0.3859"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   6%|▋         | 64/1000 [39:52<14:01:39, 53.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 64/1000, Total Reward: 6.0, Epsilon: 0.3801"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   6%|▋         | 65/1000 [40:51<14:25:10, 55.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 65/1000, Total Reward: 7.0, Epsilon: 0.3744"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   7%|▋         | 66/1000 [41:43<14:06:37, 54.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 66/1000, Total Reward: 10.0, Epsilon: 0.3688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   7%|▋         | 67/1000 [42:49<15:01:55, 58.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 67/1000, Total Reward: 15.0, Epsilon: 0.3633"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   7%|▋         | 68/1000 [43:56<15:41:11, 60.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 68/1000, Total Reward: 10.0, Epsilon: 0.3578"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   7%|▋         | 69/1000 [44:49<15:03:27, 58.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 69/1000, Total Reward: 7.0, Epsilon: 0.3525"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   7%|▋         | 70/1000 [45:39<14:26:35, 55.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 70/1000, Total Reward: 11.0, Epsilon: 0.3472"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   7%|▋         | 71/1000 [46:36<14:29:59, 56.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 71/1000, Total Reward: 8.0, Epsilon: 0.3420"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   7%|▋         | 72/1000 [47:40<15:07:11, 58.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 72/1000, Total Reward: 10.0, Epsilon: 0.3368"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   7%|▋         | 73/1000 [48:33<14:35:48, 56.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 73/1000, Total Reward: 7.0, Epsilon: 0.3318"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   7%|▋         | 74/1000 [49:29<14:33:47, 56.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 74/1000, Total Reward: 8.0, Epsilon: 0.3268"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   8%|▊         | 75/1000 [50:19<14:04:00, 54.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 75/1000, Total Reward: 8.0, Epsilon: 0.3219"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   8%|▊         | 76/1000 [51:14<14:04:14, 54.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 76/1000, Total Reward: 9.0, Epsilon: 0.3171"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   8%|▊         | 77/1000 [52:38<16:16:14, 63.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 77/1000, Total Reward: 8.0, Epsilon: 0.3123"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   8%|▊         | 78/1000 [53:54<17:13:13, 67.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 78/1000, Total Reward: 9.0, Epsilon: 0.3076"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   8%|▊         | 79/1000 [54:58<16:55:34, 66.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous episode: Episode: 79/1000, Total Reward: 9.0, Epsilon: 0.3030"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for episode in tqdm(range(num_episodes), desc='Episode Progress', position=0):\n",
    "    state, _ = env.reset()\n",
    "    episode_reward = 0\n",
    "    done = False\n",
    "\n",
    "    for step in range(max_steps_per_episode):\n",
    "        if np.random.rand() <= epsilon:\n",
    "            action = env.action_space.sample()  # Exploration\n",
    "        else:\n",
    "            q_values = model.predict(np.array([state]), verbose=None)[0]\n",
    "            action = np.argmax(q_values)  # Exploitation\n",
    "\n",
    "        # Ensure action is within bounds\n",
    "        action = np.clip(action, 0, num_actions - 1)\n",
    "\n",
    "        next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        episode_reward += reward\n",
    "\n",
    "        memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    # Experience replay\n",
    "    if len(memory) >= batch_size:\n",
    "        minibatch = random.sample(memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = reward + gamma * np.amax(model.predict(np.array([next_state]), verbose=None)[0])\n",
    "\n",
    "            target_f = model.predict(np.array([state]), verbose=None)\n",
    "            target_f[0][action] = target\n",
    "            model.fit(np.array([state]), target_f, epochs=1, verbose=None)\n",
    "\n",
    "    # Decay exploration rate\n",
    "    if epsilon > epsilon_min:\n",
    "        epsilon *= epsilon_decay\n",
    "\n",
    "    print(f\"\\rPrevious episode: Episode: {episode + 1}/{num_episodes}, Total Reward: {episode_reward}, Epsilon: {epsilon:.4f}\", end=\"\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('weights/brennan.weights.h5') # Change this to 'weights/[yourname].weights.h5'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
